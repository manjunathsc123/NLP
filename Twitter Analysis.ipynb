{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Librariers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, SpatialDropout1D, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Twitter_Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Unique Values and Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  1., nan])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    4\n",
       "category      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130448</th>\n",
       "      <td>the foundation stone northeast gas grid inaugu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155642</th>\n",
       "      <td>dear terrorists you can run but you cant hide ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155698</th>\n",
       "      <td>offense the best defence with mission shakti m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155770</th>\n",
       "      <td>have always heard politicians backing out thei...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158693</th>\n",
       "      <td>modi government plans felicitate the faceless ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159442</th>\n",
       "      <td>chidambaram gives praises modinomics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160559</th>\n",
       "      <td>the reason why modi contested from seats 2014 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "130448  the foundation stone northeast gas grid inaugu...       NaN\n",
       "155642  dear terrorists you can run but you cant hide ...       NaN\n",
       "155698  offense the best defence with mission shakti m...       NaN\n",
       "155770  have always heard politicians backing out thei...       NaN\n",
       "158693  modi government plans felicitate the faceless ...       NaN\n",
       "159442               chidambaram gives praises modinomics       NaN\n",
       "160559  the reason why modi contested from seats 2014 ...       NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['category'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158694</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159443</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160560</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       clean_text  category\n",
       "148           NaN       0.0\n",
       "158694        NaN      -1.0\n",
       "159443        NaN       0.0\n",
       "160560        NaN       1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['clean_text'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['clean_text'].isna()].index, inplace=True)\n",
    "df.drop(df[df['category'].isna()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162969 non-null  object \n",
      " 1   category    162969 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Count Vectorizer for converting text to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(max_features=10000)\n",
    "vec.fit(df['clean_text'])\n",
    "\n",
    "trn, val = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "trn_abs = vec.transform(trn['clean_text'])\n",
    "val_abs = vec.transform(val['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report for Countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.948947659078358"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "clf = OneVsRestClassifier(LogisticRegression(C = 10, n_jobs=-1))\n",
    "clf.fit(trn_abs, trn['category'])\n",
    "\n",
    "val_preds = clf.predict(val_abs)\n",
    "f1_score(val['category'], val_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948947659078358\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(val_abs, val['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.948947659078358"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(val['category'], val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9572,   264,   855],\n",
       "       [  198, 16215,   231],\n",
       "       [  687,   261, 20608]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(val['category'], val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.90      0.91     10691\n",
      "         0.0       0.97      0.97      0.97     16644\n",
      "         1.0       0.95      0.96      0.95     21556\n",
      "\n",
      "    accuracy                           0.95     48891\n",
      "   macro avg       0.94      0.94      0.94     48891\n",
      "weighted avg       0.95      0.95      0.95     48891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val['category'], val_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TFIDF Vectorizer for converting text to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(max_features=10000)\n",
    "_ = vec.fit(list(df['clean_text']))\n",
    "\n",
    "trn_abs = vec.transform(trn['clean_text'])\n",
    "val_abs = vec.transform(val['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9446728436726596"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LogisticRegression(C = 10, n_jobs=-1))\n",
    "_ = clf.fit(trn_abs, trn['category'])\n",
    "\n",
    "val_preds = clf.predict(val_abs)\n",
    "f1_score(val['category'], val_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9446728436726596\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(val_abs, val['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Embeding Layer for converting text to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer(num_words = 1000000)\n",
    "# fit\n",
    "tok.fit_on_texts(df['clean_text'].str.lower().tolist())\n",
    "\n",
    "vocab_size = len(tok.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = tok.texts_to_sequences(trn['clean_text'])\n",
    "X_val = tok.texts_to_sequences(val['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "X_trn = pad_sequences(X_trn, maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 50)           5683950   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "Fully_Connected (Dense)      (None, 200)               2000200   \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 7,684,351\n",
      "Trainable params: 7,684,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,\n",
    "                    output_dim=embedding_dim,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation='relu', name = 'Fully_Connected'))\n",
    "model.add(Dense(1, activation='sigmoid', name = 'Output'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "446/446 [==============================] - 39s 87ms/step - loss: -28.1283 - accuracy: 0.5105 - val_loss: -138.5534 - val_accuracy: 0.5538\n",
      "Epoch 2/20\n",
      "446/446 [==============================] - 41s 91ms/step - loss: -728.8243 - accuracy: 0.5650 - val_loss: -1486.3285 - val_accuracy: 0.5420\n",
      "Epoch 3/20\n",
      "446/446 [==============================] - 39s 87ms/step - loss: -3563.3855 - accuracy: 0.5649 - val_loss: -5165.7642 - val_accuracy: 0.5463\n",
      "Epoch 4/20\n",
      "446/446 [==============================] - 39s 87ms/step - loss: -9755.7129 - accuracy: 0.5655 - val_loss: -12035.9102 - val_accuracy: 0.5581\n",
      "Epoch 5/20\n",
      "446/446 [==============================] - 39s 87ms/step - loss: -20370.9512 - accuracy: 0.5657 - val_loss: -22942.1309 - val_accuracy: 0.5635\n",
      "Epoch 6/20\n",
      "446/446 [==============================] - 39s 88ms/step - loss: -36208.3164 - accuracy: 0.5663 - val_loss: -38113.1914 - val_accuracy: 0.5541\n",
      "Epoch 7/20\n",
      "446/446 [==============================] - 40s 89ms/step - loss: -57623.6914 - accuracy: 0.5658 - val_loss: -57773.5898 - val_accuracy: 0.5444\n",
      "Epoch 8/20\n",
      "446/446 [==============================] - 39s 88ms/step - loss: -85055.6484 - accuracy: 0.5668 - val_loss: -82774.3203 - val_accuracy: 0.5507\n",
      "Epoch 9/20\n",
      "446/446 [==============================] - 39s 88ms/step - loss: -119144.0938 - accuracy: 0.5654 - val_loss: -112998.7031 - val_accuracy: 0.5479\n",
      "Epoch 10/20\n",
      "446/446 [==============================] - 40s 89ms/step - loss: -159923.3125 - accuracy: 0.5663 - val_loss: -148668.8594 - val_accuracy: 0.5484\n",
      "Epoch 11/20\n",
      "446/446 [==============================] - 39s 88ms/step - loss: -207757.1094 - accuracy: 0.5657 - val_loss: -190310.9531 - val_accuracy: 0.5539\n",
      "Epoch 12/20\n",
      "446/446 [==============================] - 39s 88ms/step - loss: -262940.3750 - accuracy: 0.5670 - val_loss: -237289.5000 - val_accuracy: 0.5472\n",
      "Epoch 13/20\n",
      "446/446 [==============================] - 40s 91ms/step - loss: -326008.4688 - accuracy: 0.5655 - val_loss: -291322.0938 - val_accuracy: 0.5491\n",
      "Epoch 14/20\n",
      "446/446 [==============================] - 40s 89ms/step - loss: -397382.1875 - accuracy: 0.5663 - val_loss: -352039.0625 - val_accuracy: 0.5543\n",
      "Epoch 15/20\n",
      "446/446 [==============================] - 40s 90ms/step - loss: -477278.0625 - accuracy: 0.5659 - val_loss: -419697.0625 - val_accuracy: 0.5594\n",
      "Epoch 16/20\n",
      "446/446 [==============================] - 41s 92ms/step - loss: -566021.1250 - accuracy: 0.5662 - val_loss: -494137.4688 - val_accuracy: 0.5512\n",
      "Epoch 17/20\n",
      "446/446 [==============================] - 40s 91ms/step - loss: -663554.6875 - accuracy: 0.5661 - val_loss: -575993.5000 - val_accuracy: 0.5593\n",
      "Epoch 18/20\n",
      "446/446 [==============================] - 40s 91ms/step - loss: -770669.5000 - accuracy: 0.5671 - val_loss: -664463.9375 - val_accuracy: 0.5475\n",
      "Epoch 19/20\n",
      "446/446 [==============================] - 39s 88ms/step - loss: -887931.1875 - accuracy: 0.5660 - val_loss: -762464.7500 - val_accuracy: 0.5529\n",
      "Epoch 20/20\n",
      "446/446 [==============================] - 39s 88ms/step - loss: -1015398.2500 - accuracy: 0.5661 - val_loss: -868144.1250 - val_accuracy: 0.5512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26c6e6e8708>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_trn, trn['category'], validation_data=(X_val, val['category']), verbose=True, epochs=20, batch_size=256,\n",
    "          callbacks = [tf.keras.callbacks.ReduceLROnPlateau()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48998339001155183"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(val['category'], np.round(val_preds), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 10580,   111],\n",
       "       [    0, 16618,    26],\n",
       "       [    0, 11223, 10333]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(val['category'], np.round(val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00     10691\n",
      "         0.0       0.43      1.00      0.60     16644\n",
      "         1.0       0.99      0.48      0.65     21556\n",
      "\n",
      "    accuracy                           0.55     48891\n",
      "   macro avg       0.47      0.49      0.42     48891\n",
      "weighted avg       0.58      0.55      0.49     48891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val['category'], np.round(val_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
